{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ce860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stationary_distribution(G, teleportation=0.15, tol=1e-8, max_iter=100):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution for a weighted directed graph G,\n",
    "    using a PageRank-like power method with teleportation.\n",
    "    \n",
    "    The random walker with probability (1 - teleportation) follows\n",
    "    out-links proportional to their weight, and with probability \n",
    "    teleportation jumps uniformly to any node.\n",
    "    \n",
    "    Parameters:\n",
    "      G:             A NetworkX DiGraph with optional 'weight' on edges.\n",
    "      teleportation: The teleportation probability (typically 0.15; i.e. d=0.85).\n",
    "      tol:           Convergence tolerance.\n",
    "      max_iter:      Maximum number of iterations.\n",
    "      \n",
    "    Returns:\n",
    "      A dictionary mapping each node to its stationary probability.\n",
    "    \"\"\"\n",
    "    # Initialize with a uniform distribution\n",
    "    N = G.number_of_nodes()\n",
    "    p = {node: 1.0 / N for node in G.nodes()}\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        # Start with the teleportation contribution for every node.\n",
    "        new_p = {node: teleportation / N for node in G.nodes()}\n",
    "        \n",
    "        # For each node, distribute its probability mass along its outgoing edges.\n",
    "        for node in G.nodes():\n",
    "            # Get all outgoing edges from node along with their weight.\n",
    "            out_edges = list(G.out_edges(node, data=True))\n",
    "            if len(out_edges) == 0:\n",
    "                # Final node: no outlinks. Distribute its (follow) probability uniformly.\n",
    "                contribution = (1 - teleportation) * p[node] / N\n",
    "                for dest in G.nodes():\n",
    "                    new_p[dest] += contribution\n",
    "            else:\n",
    "                # Total weight of node's out-going links.\n",
    "                total_weight = sum(data.get('weight', 1) for (_, _, data) in out_edges)\n",
    "                # Distribute node's probability mass proportional to each link’s weight.\n",
    "                for (_, neighbor, data) in out_edges:\n",
    "                    weight = data.get('weight', 1)\n",
    "                    new_p[neighbor] += (1 - teleportation) * p[node] * (weight / total_weight)\n",
    "                    \n",
    "        # Check convergence (L1 norm)\n",
    "        err = sum(abs(new_p[node] - p[node]) for node in G.nodes())\n",
    "        p = new_p\n",
    "        if err < tol:\n",
    "            break\n",
    "    return p\n",
    "\n",
    "def compute_map_equation(G, partition, p, teleportation=0.15):\n",
    "    \"\"\"\n",
    "    Computes the map equation (description length L) for a given partition of the graph.\n",
    "    \n",
    "    The graph G is a weighted, directed graph (NetworkX DiGraph). The partition is\n",
    "    a dictionary mapping nodes to module IDs. The stationary distribution p\n",
    "    is a dictionary {node: probability} computed previously. \n",
    "    \n",
    "    The exit probability for a node is computed from the (1 - teleportation) part of the dynamics,\n",
    "    i.e., only flows that follow actual links (and leave the current module) are coded.\n",
    "    \n",
    "    Returns:\n",
    "      L_total: The total description length (in bits) for the partition.\n",
    "    \"\"\"\n",
    "    # Group nodes by their assigned module.\n",
    "    modules = {}\n",
    "    for node, module in partition.items():\n",
    "        modules.setdefault(module, []).append(node)\n",
    "    \n",
    "    # Pre-compute the total out-weight of each node.\n",
    "    out_weight = {}\n",
    "    for node in G.nodes():\n",
    "        out_edges = list(G.out_edges(node, data=True))\n",
    "        if len(out_edges) == 0:\n",
    "            out_weight[node] = 0\n",
    "        else:\n",
    "            total = sum(data.get('weight', 1) for (_, _, data) in out_edges)\n",
    "            out_weight[node] = total\n",
    "    \n",
    "    # For each module, compute the total node probability and the exit probability.\n",
    "    module_info = {}\n",
    "    for module, nodes in modules.items():\n",
    "        p_module = sum(p[node] for node in nodes)\n",
    "        exit_module = 0.0\n",
    "        # For each node in the module, add the probability that the random walker leaves the module.\n",
    "        for node in nodes:\n",
    "            if out_weight[node] > 0:\n",
    "                # Check each outlink; if the neighbor lies outside the module then count this flow.\n",
    "                for _, neighbor, data in G.out_edges(node, data=True):\n",
    "                    if partition[neighbor] != module:\n",
    "                        weight = data.get('weight', 1)\n",
    "                        exit_module += p[node] * (1 - teleportation) * (weight / out_weight[node])\n",
    "        module_info[module] = {'p_module': p_module, 'exit': exit_module, 'nodes': nodes}\n",
    "    \n",
    "    # Total exit probability (the inter-module flow) summed over all modules.\n",
    "    q_exit = sum(info['exit'] for info in module_info.values())\n",
    "    \n",
    "    # Compute the entropy of the inter-module (exit) codebook.\n",
    "    H_exit = 0.0\n",
    "    if q_exit > 0:\n",
    "        for info in module_info.values():\n",
    "            if info['exit'] > 0:\n",
    "                prob = info['exit'] / q_exit\n",
    "                H_exit -= prob * math.log(prob, 2)\n",
    "    \n",
    "    # Compute the contribution to L from within each module.\n",
    "    L_within = 0.0\n",
    "    for module, info in module_info.items():\n",
    "        p_module = info['p_module']\n",
    "        exit_module = info['exit']\n",
    "        total_flow = p_module + exit_module  # Total weight for the module's codebook.\n",
    "        H_module = 0.0\n",
    "        # First, include the exit code for the module.\n",
    "        if exit_module > 0:\n",
    "            prob_exit = exit_module / total_flow\n",
    "            H_module -= prob_exit * math.log(prob_exit, 2)\n",
    "        # Next, add the contribution from each node in the module.\n",
    "        for node in info['nodes']:\n",
    "            if p[node] > 0:\n",
    "                prob_node = p[node] / total_flow\n",
    "                H_module -= prob_node * math.log(prob_node, 2)\n",
    "        # Multiply the module’s entropy by its total weight.\n",
    "        L_within += total_flow * H_module\n",
    "    \n",
    "    # Combine the inter-module and within-module parts.\n",
    "    L_total = q_exit * H_exit + L_within\n",
    "    return L_total\n",
    "\n",
    "def infomap_greedy(G, teleportation=0.15, max_iter=100):\n",
    "    \"\"\"\n",
    "    Finds a (locally) optimal partition of graph G to minimize the map equation L\n",
    "    using a greedy algorithm.\n",
    "    \n",
    "    The algorithm initializes with every node in its own module and then repeatedly \n",
    "    moves each node to a candidate module (among its neighbors' modules) if the move \n",
    "    reduces the total description length.\n",
    "    \n",
    "    Parameters:\n",
    "      G:            A NetworkX DiGraph representing the network.\n",
    "      teleportation: The teleportation probability for the random walker.\n",
    "      max_iter:     Maximum iterations over all nodes.\n",
    "      \n",
    "    Returns:\n",
    "      partition:  A dictionary mapping node to its module label.\n",
    "      current_L:  The final (optimized) description length.\n",
    "    \"\"\"\n",
    "    # Initialize partition: each node in its own module.\n",
    "    partition = {node: node for node in G.nodes()}\n",
    "    # Compute the stationary distribution for the random walk on G.\n",
    "    p = compute_stationary_distribution(G, teleportation=teleportation)\n",
    "    # Compute the initial description length.\n",
    "    current_L = compute_map_equation(G, partition, p, teleportation=teleportation)\n",
    "    \n",
    "    improvement = True\n",
    "    iter_count = 0\n",
    "    # Repeat until no move improves L or maximum iterations is reached.\n",
    "    while improvement and iter_count < max_iter:\n",
    "        improvement = False\n",
    "        iter_count += 1\n",
    "        nodes = list(G.nodes())\n",
    "        random.shuffle(nodes)  # Process nodes in random order to reduce bias.\n",
    "        for node in nodes:\n",
    "            current_module = partition[node]\n",
    "            # Determine candidate modules:\n",
    "            # (Use both out-going and in-coming neighbor modules.)\n",
    "            candidate_modules = set()\n",
    "            for (_, neighbor) in G.out_edges(node):\n",
    "                candidate_modules.add(partition[neighbor])\n",
    "            for (neighbor, _) in G.in_edges(node):\n",
    "                candidate_modules.add(partition[neighbor])\n",
    "            # Always include the current module.\n",
    "            candidate_modules.add(current_module)\n",
    "            \n",
    "            best_module = current_module\n",
    "            best_L = current_L\n",
    "            # Test moving node to each candidate module.\n",
    "            for module in candidate_modules:\n",
    "                if module == current_module:\n",
    "                    continue\n",
    "                # Temporarily reassign node to the candidate module.\n",
    "                old_module = partition[node]\n",
    "                partition[node] = module\n",
    "                new_L = compute_map_equation(G, partition, p, teleportation=teleportation)\n",
    "                # If the move improves (i.e. lowers) L, record it.\n",
    "                if new_L < best_L:\n",
    "                    best_L = new_L\n",
    "                    best_module = module\n",
    "                # Revert the temporary move.\n",
    "                partition[node] = old_module\n",
    "            # If a better module was found, perform the move permanently.\n",
    "            if best_module != current_module:\n",
    "                partition[node] = best_module\n",
    "                current_L = best_L\n",
    "                improvement = True\n",
    "        # (A more advanced implementation would also try merging modules and\n",
    "        # refining using techniques like simulated annealing.)\n",
    "    return partition, current_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f679af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Partition (node -> module):\n",
      "  Node 1 -> Module 2\n",
      "  Node 2 -> Module 2\n",
      "  Node 3 -> Module 2\n",
      "  Node 4 -> Module 5\n",
      "  Node 5 -> Module 5\n",
      "  Node 6 -> Module 5\n",
      "  Node 7 -> Module 5\n",
      "\n",
      "Final map equation L (in bits per step): 2.1034831759741053\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes (for clarity, nodes are labeled with integers)\n",
    "for i in range(1, 8):\n",
    "    G.add_node(i)\n",
    "\n",
    "# Cluster 1: nodes 1,2,3 (strongly connected)\n",
    "G.add_edge(1, 2, weight=3)\n",
    "G.add_edge(2, 1, weight=3)\n",
    "G.add_edge(2, 3, weight=3)\n",
    "G.add_edge(3, 1, weight=3)\n",
    "\n",
    "# Cluster 2: nodes 4,5,6,7 (strongly connected)\n",
    "G.add_edge(4, 5, weight=3)\n",
    "G.add_edge(5, 6, weight=3)\n",
    "G.add_edge(6, 7, weight=3)\n",
    "G.add_edge(7, 4, weight=3)\n",
    "\n",
    "# Few links between clusters (weaker connections)\n",
    "G.add_edge(3, 4, weight=1)\n",
    "G.add_edge(7, 1, weight=1)\n",
    "\n",
    "# Run the greedy Infomap-like community detection.\n",
    "partition, L_value = infomap_greedy(G, teleportation=0.15, max_iter=100)\n",
    "print(\"Optimized Partition (node -> module):\")\n",
    "for node in sorted(partition.keys()):\n",
    "    print(f\"  Node {node} -> Module {partition[node]}\")\n",
    "print(\"\\nFinal map equation L (in bits per step):\", L_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
